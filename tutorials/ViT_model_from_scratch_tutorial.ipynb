{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "nytAF1Qi7zF2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "QD_qDb_LcgER"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ],
      "metadata": {
        "id": "7Gz3fcli70ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training parameters\n",
        "B = 32 # batch size\n",
        "\n",
        "# image parameters\n",
        "C = 3\n",
        "H = 128\n",
        "W = 128\n",
        "x = torch.rand(B, C, H, W)\n",
        "\n",
        "#model parameters\n",
        "D = 64 # hidden size\n",
        "P = 4 #patch size\n",
        "N = int(H*W/P**2)#number of tokens\n",
        "k = 4 # number of attention heads\n",
        "Dh = int(D/k) # attention head size\n",
        "p = 0.1 # dropout rate\n",
        "mlp_size = D*4 # mlp size\n",
        "L = 4 # number of transformer blocks\n",
        "n_classes = 3 # number of classes\n",
        "\n",
        "print(\"B:\", B)\n",
        "print(\"C:\", C)\n",
        "print(\"H:\", H)\n",
        "print(\"W:\", W)\n",
        "print(\"D:\", D)\n",
        "print(\"P:\", P)\n",
        "print(\"N:\", N)\n",
        "print(\"k:\", k)\n",
        "print(\"Dh:\", Dh)\n",
        "print(\"p:\", p)\n",
        "print(\"mlp_size:\", mlp_size)\n",
        "print(\"L:\", L)\n",
        "print(\"n_classes:\", n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roY_TYAnKbaN",
        "outputId": "7a239e66-8d69-4539-f760-d4cd345073b0"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B: 32\n",
            "C: 3\n",
            "H: 128\n",
            "W: 128\n",
            "D: 64\n",
            "P: 4\n",
            "N: 1024\n",
            "k: 4\n",
            "Dh: 16\n",
            "p: 0.1\n",
            "mlp_size: 256\n",
            "L: 4\n",
            "n_classes: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding\n"
      ],
      "metadata": {
        "id": "CGY-IK6N72Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Embeddings [Patch, Class, with Position Embeddings]\n",
        "\n",
        "class Embedding(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Embedding, self).__init__()\n",
        "\n",
        "        self.unfold = nn.Unfold(kernel_size=P, stride=P) # function to create patch vectors (x_p^i)\n",
        "        self.project = nn.Linear(P**2 * C, D) # patch tokens (E)\n",
        "        self.cls_token = nn.Parameter(torch.randn((1, 1, D))) # function to create unbatched class token (x_class) as trainable parameter\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, N+1, D)) # function to create unbatched position embedding (E_pos) as trainable parameter\n",
        "        self.dropout = nn.Dropout(p) #dropout\n",
        "\n",
        "        #why unbatched? because we are setting the parameters and functions here.\n",
        "        # giving batched will increase the parameter size without effectively increasing the parameters\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        print(\"###Embedding###\")\n",
        "        print(\"input image:\", x.shape)\n",
        "        x = self.unfold(x).transpose(1,2) # patch vectors (x_p^i)\n",
        "        print(\"x_p^i:\", x.shape)\n",
        "        x = self.project(x)\n",
        "        print(\"x_p^i*E: \", x.shape) # tokens for patches (x_p^i*E)\n",
        "        cls_token = self.cls_token # unbatched class token (x_class)\n",
        "        print(\"unbatched x_class:\", cls_token.shape)\n",
        "        cls_token = self.cls_token.expand(B, -1, -1) # batched class token (x_class)\n",
        "        print(\"x_class:\", cls_token.shape)\n",
        "        x = torch.cat((cls_token, x), dim = 1) # final image token embedding\n",
        "        print(\"patch embedding:\", x.shape)\n",
        "        pos_embedding = self.pos_embedding # unbatched position embedding (E_pos)\n",
        "        print(\"unbatched E_pos:\", pos_embedding.shape)\n",
        "        pos_embedding = pos_embedding.expand(B, -1, -1) # batched position embedding (E_pos)\n",
        "        print(\"E_pos:\", pos_embedding.shape)\n",
        "        z0 = x + pos_embedding # adding the batched position and image embedding\n",
        "        print(\"z0:\", z0.shape)\n",
        "        z0 = self.dropout(z0) # dropout\n",
        "        return z0"
      ],
      "metadata": {
        "id": "CxMCWZWW3AJl"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Embedding()\n",
        "y = model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wJqoKCfA7eqv",
        "outputId": "6f0d06dd-a5bb-45a9-bd60-37564a3b4a30"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###Embedding###\n",
            "input image: torch.Size([32, 3, 128, 128])\n",
            "x_p^i: torch.Size([32, 1024, 48])\n",
            "x_p^i*E:  torch.Size([32, 1024, 64])\n",
            "unbatched x_class: torch.Size([1, 1, 64])\n",
            "x_class: torch.Size([32, 1, 64])\n",
            "patch embedding: torch.Size([32, 1025, 64])\n",
            "unbatched E_pos: torch.Size([1, 1025, 64])\n",
            "E_pos: torch.Size([32, 1025, 64])\n",
            "z0: torch.Size([32, 1025, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Head Attention"
      ],
      "metadata": {
        "id": "GM6jIdPl74sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Single Head Attention\n",
        "\n",
        "\n",
        "class Single_Head_Attention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Single_Head_Attention, self).__init__()\n",
        "\n",
        "        self.U_qkv = nn.Linear(D, 3*Dh) # U_qkv\n",
        "        self.softmax = nn.Softmax(dim = -1) # softmax along the last dimension\n",
        "\n",
        "    def forward(self, z):\n",
        "\n",
        "      print(\"###Single Head Attention###\")\n",
        "      print(\"z:\", z.shape)\n",
        "      qkv = self.U_qkv(z) # qkv\n",
        "      print(\"qkv:\", qkv.shape)\n",
        "      q = qkv[:, :, :Dh] # q\n",
        "      print(\"q:\", q.shape)\n",
        "      k = qkv[:, :, Dh:2*Dh] # k\n",
        "      print(\"k:\", k.shape)\n",
        "      v = qkv[:, :, 2*Dh:] # v\n",
        "      print(\"v:\", v.shape)\n",
        "      qkTbysqrtDh = torch.matmul(q, k.transpose(-2, -1))/math.sqrt(Dh) # qk^T/sqrtDh\n",
        "      print(\"qkTbysqrtDh:\", qkTbysqrtDh.shape)\n",
        "      A = self.softmax(qkTbysqrtDh) # A\n",
        "      print(\"A:\", A.shape)\n",
        "      SAz = torch.matmul(A, v) # z = Av\n",
        "      print(\"SA(z):\", SAz.shape)\n",
        "\n",
        "      return SAz"
      ],
      "metadata": {
        "id": "0j6AcCE67-kT"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Embedding()\n",
        "y = model(x)\n",
        "model = Single_Head_Attention()\n",
        "z = model(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRLIY-lc7NgU",
        "outputId": "2c7c39ba-f993-4545-9991-df497b1d165b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###Embedding###\n",
            "input image: torch.Size([32, 3, 128, 128])\n",
            "x_p^i: torch.Size([32, 1024, 48])\n",
            "x_p^i*E:  torch.Size([32, 1024, 64])\n",
            "unbatched x_class: torch.Size([1, 1, 64])\n",
            "x_class: torch.Size([32, 1, 64])\n",
            "patch embedding: torch.Size([32, 1025, 64])\n",
            "unbatched E_pos: torch.Size([1, 1025, 64])\n",
            "E_pos: torch.Size([32, 1025, 64])\n",
            "z0: torch.Size([32, 1025, 64])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi Head Self Attention\n"
      ],
      "metadata": {
        "id": "3bbuyafq78N6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi Head Self Attention\n",
        "\n",
        "class Multi_Head_Self_Attention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Multi_Head_Self_Attention, self).__init__()\n",
        "\n",
        "        self.heads = nn.ModuleList([Single_Head_Attention() for _ in range(k)]) # k heads\n",
        "        self.U_msa = nn.Linear(D, D) # U_msa\n",
        "        self.dropout = nn.Dropout(p) #dropout\n",
        "\n",
        "    def forward(self, z):\n",
        "\n",
        "      print(\"###Multi Head Attention###\")\n",
        "      print(\"z:\", z.shape)\n",
        "      ConSAz = torch.cat([head(z) for head in self.heads], dim = -1)\n",
        "      print(\"ConSA(z):\", ConSAz.shape)\n",
        "      msaz = self.U_msa(z) # MSA(z)\n",
        "      print(\"MSA(z):\", msaz.shape)\n",
        "      msaz = self.dropout(msaz) # dropout\n",
        "\n",
        "      return msaz"
      ],
      "metadata": {
        "id": "P2EB5IdffhuK"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Embedding()\n",
        "y = model(x)\n",
        "model = Multi_Head_Self_Attention()\n",
        "z = model(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYExQpMXFhvi",
        "outputId": "a3f17c55-190b-4db5-bbb2-6667fecac95c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###Embedding###\n",
            "input image: torch.Size([32, 3, 128, 128])\n",
            "x_p^i: torch.Size([32, 1024, 48])\n",
            "x_p^i*E:  torch.Size([32, 1024, 64])\n",
            "unbatched x_class: torch.Size([1, 1, 64])\n",
            "x_class: torch.Size([32, 1, 64])\n",
            "patch embedding: torch.Size([32, 1025, 64])\n",
            "unbatched E_pos: torch.Size([1, 1025, 64])\n",
            "E_pos: torch.Size([32, 1025, 64])\n",
            "z0: torch.Size([32, 1025, 64])\n",
            "###Multi Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "ConSA(z): torch.Size([32, 1025, 64])\n",
            "MSA(z): torch.Size([32, 1025, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP"
      ],
      "metadata": {
        "id": "9iKIFivVRE52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.U_mlp = nn.Linear(D, mlp_size)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.U_mlp2 = nn.Linear(mlp_size, D)\n",
        "        self.dropout = nn.Dropout(p)\n",
        "\n",
        "    def forward(self, z):\n",
        "\n",
        "      print(\"###MLP###\")\n",
        "      print(\"z:\", z.shape)\n",
        "      z = self.U_mlp(z) # mlp\n",
        "      print(\"mlp(z):\", z.shape)\n",
        "      z = self.gelu(z) # gelu\n",
        "      print(\"gelu(mlp(z)):\", z.shape)\n",
        "      z = self.dropout(z) # dropout\n",
        "      z = self.U_mlp2(z) # mlp2\n",
        "      print(\"mlp2(gelu(mlp(z))):\", z.shape)\n",
        "      z = self.gelu(z) # gelu\n",
        "      print(\"gelu(mlp2(gelu(mlp(z)))):\", z.shape)\n",
        "      z = self.dropout(z) # dropout\n",
        "\n",
        "      return z"
      ],
      "metadata": {
        "id": "d9gqoo-ffnor"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Embedding()\n",
        "y = model(x)\n",
        "model = Multi_Head_Self_Attention()\n",
        "z = model(y)\n",
        "model = MLP()\n",
        "z = model(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vbMXdFFPbu3",
        "outputId": "4d4aa4ea-3ac5-4eec-d59f-0d72c15435cc"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###Embedding###\n",
            "input image: torch.Size([32, 3, 128, 128])\n",
            "x_p^i: torch.Size([32, 1024, 48])\n",
            "x_p^i*E:  torch.Size([32, 1024, 64])\n",
            "unbatched x_class: torch.Size([1, 1, 64])\n",
            "x_class: torch.Size([32, 1, 64])\n",
            "patch embedding: torch.Size([32, 1025, 64])\n",
            "unbatched E_pos: torch.Size([1, 1025, 64])\n",
            "E_pos: torch.Size([32, 1025, 64])\n",
            "z0: torch.Size([32, 1025, 64])\n",
            "###Multi Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "ConSA(z): torch.Size([32, 1025, 64])\n",
            "MSA(z): torch.Size([32, 1025, 64])\n",
            "###MLP###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "mlp(z): torch.Size([32, 1025, 256])\n",
            "gelu(mlp(z)): torch.Size([32, 1025, 256])\n",
            "mlp2(gelu(mlp(z))): torch.Size([32, 1025, 64])\n",
            "gelu(mlp2(gelu(mlp(z)))): torch.Size([32, 1025, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Block"
      ],
      "metadata": {
        "id": "I3KI0_96RGUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Block\n",
        "\n",
        "class Transformer_Block(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Transformer_Block, self).__init__()\n",
        "\n",
        "        self.layernorm_1 = nn.LayerNorm(D)\n",
        "        self.msa = Multi_Head_Self_Attention()\n",
        "        self.layernorm_2 = nn.LayerNorm(D)\n",
        "        self.mlp = MLP()\n",
        "\n",
        "    def forward(self, z):\n",
        "\n",
        "      print(\"###Transformer Block###\")\n",
        "      print(\"z:\", z.shape)\n",
        "      z1 = self.layernorm_1(z) # layer norm 1 output\n",
        "      print(\"layernorm_1(z):\", z1.shape)\n",
        "      z1 = self.msa(z1) # multi head self attention\n",
        "      print(\"msa(layernorm_1(z)):\", z1.shape)\n",
        "      z2 = z + z1\n",
        "      print(\"z + msa(layernorm_1(z)):\", z2.shape)\n",
        "      z3 = self.layernorm_2(z2) # layer norm 2 output\n",
        "      print(\"layernorm_2(z + msa(layernorm_1(z))):\", z3.shape)\n",
        "      z3 = self.mlp(z3) # mlp\n",
        "      print(\"mlp(layernorm_2(z + msa(layernorm_1(z)))):\", z3.shape)\n",
        "      z4 = z2 + z3\n",
        "      print(\"z2 + mlp(layernorm_2(z + msa(layernorm_1(z)))):\", z4.shape)\n",
        "\n",
        "      return z4"
      ],
      "metadata": {
        "id": "1wQkqfM2fkE7"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Embedding()\n",
        "y = model(x)\n",
        "model = Transformer_Block()\n",
        "z = model(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6enQ9cHUoEd",
        "outputId": "45ce0c1e-592b-4127-93ec-914ac4eafac5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###Embedding###\n",
            "input image: torch.Size([32, 3, 128, 128])\n",
            "x_p^i: torch.Size([32, 1024, 48])\n",
            "x_p^i*E:  torch.Size([32, 1024, 64])\n",
            "unbatched x_class: torch.Size([1, 1, 64])\n",
            "x_class: torch.Size([32, 1, 64])\n",
            "patch embedding: torch.Size([32, 1025, 64])\n",
            "unbatched E_pos: torch.Size([1, 1025, 64])\n",
            "E_pos: torch.Size([32, 1025, 64])\n",
            "z0: torch.Size([32, 1025, 64])\n",
            "###Transformer Block###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "layernorm_1(z): torch.Size([32, 1025, 64])\n",
            "###Multi Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "ConSA(z): torch.Size([32, 1025, 64])\n",
            "MSA(z): torch.Size([32, 1025, 64])\n",
            "msa(layernorm_1(z)): torch.Size([32, 1025, 64])\n",
            "z + msa(layernorm_1(z)): torch.Size([32, 1025, 64])\n",
            "layernorm_2(z + msa(layernorm_1(z))): torch.Size([32, 1025, 64])\n",
            "###MLP###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "mlp(z): torch.Size([32, 1025, 256])\n",
            "gelu(mlp(z)): torch.Size([32, 1025, 256])\n",
            "mlp2(gelu(mlp(z))): torch.Size([32, 1025, 64])\n",
            "gelu(mlp2(gelu(mlp(z)))): torch.Size([32, 1025, 64])\n",
            "mlp(layernorm_2(z + msa(layernorm_1(z)))): torch.Size([32, 1025, 64])\n",
            "z2 + mlp(layernorm_2(z + msa(layernorm_1(z)))): torch.Size([32, 1025, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ViT (everything together)"
      ],
      "metadata": {
        "id": "mnXz69NXUoX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ViT\n",
        "\n",
        "class ViT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ViT, self).__init__()\n",
        "\n",
        "        self.embedding = Embedding()\n",
        "        self.transformer_encoder = nn.ModuleList([Transformer_Block() for _ in range(L)])\n",
        "        self.layernorm = nn.LayerNorm(D)\n",
        "        self.U_mlp = nn.Linear(D, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      print(\"###ViT###\")\n",
        "      print(\"input image:\", x.shape)\n",
        "      z = self.embedding(x)\n",
        "      print(\"z:\", z.shape)\n",
        "      for block in self.transformer_encoder:\n",
        "        z = block(z)\n",
        "      print(\"z:\", z.shape)\n",
        "      z = self.layernorm(z)\n",
        "      print(\"layernorm(z):\", z.shape)\n",
        "      z = z[:, 0, :]\n",
        "      print(\"z:\", z.shape)\n",
        "      z = self.U_mlp(z)\n",
        "      print(\"mlp(layernorm(z)):\", z.shape)\n",
        "\n",
        "      return z"
      ],
      "metadata": {
        "id": "1rfMZQhgfmfe"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ViT()\n",
        "y = model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhw_HDGEKGAS",
        "outputId": "be2ebd43-02db-483d-d74f-0560bfbe080d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###ViT###\n",
            "input image: torch.Size([32, 3, 128, 128])\n",
            "###Embedding###\n",
            "input image: torch.Size([32, 3, 128, 128])\n",
            "x_p^i: torch.Size([32, 1024, 48])\n",
            "x_p^i*E:  torch.Size([32, 1024, 64])\n",
            "unbatched x_class: torch.Size([1, 1, 64])\n",
            "x_class: torch.Size([32, 1, 64])\n",
            "patch embedding: torch.Size([32, 1025, 64])\n",
            "unbatched E_pos: torch.Size([1, 1025, 64])\n",
            "E_pos: torch.Size([32, 1025, 64])\n",
            "z0: torch.Size([32, 1025, 64])\n",
            "z: torch.Size([32, 1025, 64])\n",
            "###Transformer Block###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "layernorm_1(z): torch.Size([32, 1025, 64])\n",
            "###Multi Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "ConSA(z): torch.Size([32, 1025, 64])\n",
            "MSA(z): torch.Size([32, 1025, 64])\n",
            "msa(layernorm_1(z)): torch.Size([32, 1025, 64])\n",
            "z + msa(layernorm_1(z)): torch.Size([32, 1025, 64])\n",
            "layernorm_2(z + msa(layernorm_1(z))): torch.Size([32, 1025, 64])\n",
            "###MLP###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "mlp(z): torch.Size([32, 1025, 256])\n",
            "gelu(mlp(z)): torch.Size([32, 1025, 256])\n",
            "mlp2(gelu(mlp(z))): torch.Size([32, 1025, 64])\n",
            "gelu(mlp2(gelu(mlp(z)))): torch.Size([32, 1025, 64])\n",
            "mlp(layernorm_2(z + msa(layernorm_1(z)))): torch.Size([32, 1025, 64])\n",
            "z2 + mlp(layernorm_2(z + msa(layernorm_1(z)))): torch.Size([32, 1025, 64])\n",
            "###Transformer Block###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "layernorm_1(z): torch.Size([32, 1025, 64])\n",
            "###Multi Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "ConSA(z): torch.Size([32, 1025, 64])\n",
            "MSA(z): torch.Size([32, 1025, 64])\n",
            "msa(layernorm_1(z)): torch.Size([32, 1025, 64])\n",
            "z + msa(layernorm_1(z)): torch.Size([32, 1025, 64])\n",
            "layernorm_2(z + msa(layernorm_1(z))): torch.Size([32, 1025, 64])\n",
            "###MLP###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "mlp(z): torch.Size([32, 1025, 256])\n",
            "gelu(mlp(z)): torch.Size([32, 1025, 256])\n",
            "mlp2(gelu(mlp(z))): torch.Size([32, 1025, 64])\n",
            "gelu(mlp2(gelu(mlp(z)))): torch.Size([32, 1025, 64])\n",
            "mlp(layernorm_2(z + msa(layernorm_1(z)))): torch.Size([32, 1025, 64])\n",
            "z2 + mlp(layernorm_2(z + msa(layernorm_1(z)))): torch.Size([32, 1025, 64])\n",
            "###Transformer Block###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "layernorm_1(z): torch.Size([32, 1025, 64])\n",
            "###Multi Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "ConSA(z): torch.Size([32, 1025, 64])\n",
            "MSA(z): torch.Size([32, 1025, 64])\n",
            "msa(layernorm_1(z)): torch.Size([32, 1025, 64])\n",
            "z + msa(layernorm_1(z)): torch.Size([32, 1025, 64])\n",
            "layernorm_2(z + msa(layernorm_1(z))): torch.Size([32, 1025, 64])\n",
            "###MLP###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "mlp(z): torch.Size([32, 1025, 256])\n",
            "gelu(mlp(z)): torch.Size([32, 1025, 256])\n",
            "mlp2(gelu(mlp(z))): torch.Size([32, 1025, 64])\n",
            "gelu(mlp2(gelu(mlp(z)))): torch.Size([32, 1025, 64])\n",
            "mlp(layernorm_2(z + msa(layernorm_1(z)))): torch.Size([32, 1025, 64])\n",
            "z2 + mlp(layernorm_2(z + msa(layernorm_1(z)))): torch.Size([32, 1025, 64])\n",
            "###Transformer Block###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "layernorm_1(z): torch.Size([32, 1025, 64])\n",
            "###Multi Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "###Single Head Attention###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "qkv: torch.Size([32, 1025, 48])\n",
            "q: torch.Size([32, 1025, 16])\n",
            "k: torch.Size([32, 1025, 16])\n",
            "v: torch.Size([32, 1025, 16])\n",
            "qkTbysqrtDh: torch.Size([32, 1025, 1025])\n",
            "A: torch.Size([32, 1025, 1025])\n",
            "SA(z): torch.Size([32, 1025, 16])\n",
            "ConSA(z): torch.Size([32, 1025, 64])\n",
            "MSA(z): torch.Size([32, 1025, 64])\n",
            "msa(layernorm_1(z)): torch.Size([32, 1025, 64])\n",
            "z + msa(layernorm_1(z)): torch.Size([32, 1025, 64])\n",
            "layernorm_2(z + msa(layernorm_1(z))): torch.Size([32, 1025, 64])\n",
            "###MLP###\n",
            "z: torch.Size([32, 1025, 64])\n",
            "mlp(z): torch.Size([32, 1025, 256])\n",
            "gelu(mlp(z)): torch.Size([32, 1025, 256])\n",
            "mlp2(gelu(mlp(z))): torch.Size([32, 1025, 64])\n",
            "gelu(mlp2(gelu(mlp(z)))): torch.Size([32, 1025, 64])\n",
            "mlp(layernorm_2(z + msa(layernorm_1(z)))): torch.Size([32, 1025, 64])\n",
            "z2 + mlp(layernorm_2(z + msa(layernorm_1(z)))): torch.Size([32, 1025, 64])\n",
            "z: torch.Size([32, 1025, 64])\n",
            "layernorm(z): torch.Size([32, 1025, 64])\n",
            "z: torch.Size([32, 64])\n",
            "mlp(layernorm(z)): torch.Size([32, 3])\n"
          ]
        }
      ]
    }
  ]
}